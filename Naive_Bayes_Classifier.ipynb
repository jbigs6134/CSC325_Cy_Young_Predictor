{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec9884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca422870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"working_data.csv\")\n",
    "\n",
    "# Separate descriptors and target\n",
    "player_descriptors = df.iloc[:, :3]\n",
    "league = df['Lg']\n",
    "cy_young_place = df['Cy_young']\n",
    "X = df.iloc[:, 3:-2]\n",
    "\n",
    "# Add league temporarily for sorting\n",
    "X['Lg'] = league\n",
    "y = cy_young_place\n",
    "\n",
    "# Create separate datasets\n",
    "x_al = X[X['Lg'] == 'AL'].drop(columns=['Lg'])\n",
    "x_nl = X[X['Lg'] == 'NL'].drop(columns=['Lg'])\n",
    "\n",
    "y_al = y[league == 'AL']\n",
    "y_nl = y[league == 'NL']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43cf812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for NL: ['WAR', 'SO', 'ERA', 'W', 'FIP', 'IP', 'ERA+', 'WHIP', 'BF', 'W-L%']\n",
      "Selected Features for AL: ['WAR', 'SO', 'FIP', 'ERA+', 'IP', 'ERA', 'BF', 'W', 'WHIP', 'GS']\n",
      "Selected Features for NL: ['WAR', 'W', 'ERA', 'CG', 'SHO', 'IP', 'SO', 'BF', 'ERA+', 'FIP']\n",
      "Selected Features for AL: ['WAR', 'W', 'CG', 'SHO', 'IP', 'SO', 'BK', 'BF', 'ERA+', 'FIP']\n"
     ]
    }
   ],
   "source": [
    "# Read selected features (from forest importance)\n",
    "with open('forest_importance_nl.json', 'r') as f:\n",
    "    selected_features_nl_importance = json.load(f)\n",
    "\n",
    "with open('forest_importance_al.json', 'r') as f:\n",
    "    selected_features_al_importance = json.load(f)\n",
    "\n",
    "# Read selected features (from Chi-squared)\n",
    "with open('chi2_selected_features_nl.json', 'r') as f:\n",
    "    selected_features_nl_chi2 = json.load(f)\n",
    "\n",
    "\n",
    "with open('chi2_selected_features_al.json', 'r') as f:\n",
    "    selected_features_al_chi2 = json.load(f)\n",
    "\n",
    "# Print selected features\n",
    "print(\"Selected Features for NL:\", selected_features_nl_importance)\n",
    "print(\"Selected Features for AL:\", selected_features_al_importance)\n",
    "print(\"Selected Features for NL:\", selected_features_nl_chi2)\n",
    "print(\"Selected Features for AL:\", selected_features_al_chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b8d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Importance\n",
    "x_nl_importance = x_nl[selected_features_nl_importance]\n",
    "x_al_importance = x_al[selected_features_al_importance]\n",
    "\n",
    "# Chi-squared Features\n",
    "x_nl_chi2 = x_nl[selected_features_nl_chi2]\n",
    "x_al_chi2 = x_al[selected_features_al_chi2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9eef4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_mlb_features(df):\n",
    "    binned_df = df.copy()\n",
    "    reverse_metrics = ['ERA', 'WHIP', 'FIP']\n",
    "    n_bins = 5\n",
    "\n",
    "    for col in binned_df.select_dtypes(include=[np.number]).columns:\n",
    "        series = binned_df[col]\n",
    "        series = series.fillna(0)\n",
    "        if series.nunique() < 2:\n",
    "            print(f\"Skipping {col}: not enough unique values to bin.\")\n",
    "            continue\n",
    "        try:\n",
    "            binned_col = pd.qcut(series, q=n_bins, labels=False, duplicates='drop')\n",
    "            if col in reverse_metrics:\n",
    "                max_label = binned_col.max()\n",
    "                binned_col = max_label - binned_col  # Reverse order\n",
    "            binned_df[col] = binned_col\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {col} due to qcut error: {e}\")\n",
    "\n",
    "    return binned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09c75d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate nl based on importance\n",
    "nl_importance = bin_mlb_features(x_nl_importance)\n",
    "nl_importance['Cy_young'] = y_nl\n",
    "nl_importance = nl_importance.to_numpy()\n",
    "\n",
    "# generate AL based on importance\n",
    "al_importance = bin_mlb_features(x_al_importance)\n",
    "al_importance['Cy_young'] = y_al\n",
    "al_importance = al_importance.to_numpy()\n",
    "\n",
    "# generate NL based on chi squared importance\n",
    "nl_chi2 = bin_mlb_features(x_nl_chi2)\n",
    "nl_chi2['Cy_young'] = y_nl\n",
    "nl_chi2 = nl_chi2.to_numpy()\n",
    "\n",
    "# generate AL based on chi squared importance\n",
    "al_chi2 = bin_mlb_features(x_al_chi2)\n",
    "al_chi2['Cy_young'] = y_al\n",
    "al_chi2 = al_chi2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20b03123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_q(data, attributes,classes,values):\n",
    "  Q_nl_importance = np.zeros((attributes,classes,values))\n",
    "\n",
    "  for attribute in range(attributes):\n",
    "    for c in range(classes):\n",
    "      for v in range(values):\n",
    "        Q_nl_importance[attribute, c ,v] = np.sum((data[:, attribute] == v) & (data[:, classes] == c)) / np.sum(data[:, values] == c)\n",
    "  return Q_nl_importance      \n",
    "        \n",
    "def find_p(data,classes,values):\n",
    "  P_nl_importance = np.zeros(values)\n",
    "\n",
    "  for c in range(values):\n",
    "    P_nl_importance[c] = np.sum(data[:,classes] == c) / len(data[:, classes])\n",
    "  \n",
    "  return P_nl_importance\n",
    "\n",
    "def calculate_c(Q_nl_importance, P_nl_importance, values=10):\n",
    "    c_nl_importance = np.zeros((values, values, values, values, values))\n",
    "\n",
    "    for v1 in range(values):\n",
    "        for v2 in range(values):\n",
    "            for v3 in range(values):\n",
    "                for v4 in range(values):\n",
    "                    for v5 in range(values):\n",
    "                        c_nl_importance[v1, v2, v3, v4, v5] = np.argmax(\n",
    "                            Q_nl_importance[0, :, v1] *\n",
    "                            Q_nl_importance[1, :, v2] *\n",
    "                            Q_nl_importance[2, :, v3] *\n",
    "                            Q_nl_importance[3, :, v4] *\n",
    "                            Q_nl_importance[4, :, v5] *\n",
    "                            P_nl_importance\n",
    "                        )\n",
    "    \n",
    "    return c_nl_importance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84076d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.8526912181303116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attributes = 10  \n",
    "classes = 10  \n",
    "values = 10  \n",
    "\n",
    "# Call the functions\n",
    "Q_nl_importance = find_q(nl_importance, attributes, classes, values)\n",
    "P_nl_importance = find_p(nl_importance, classes, values)\n",
    "c_nl_importance = calculate_c(Q_nl_importance, P_nl_importance, values)\n",
    "\n",
    "nl_importance_result = []\n",
    "nl_importance_correct = 0\n",
    "for i in range(len(nl_importance)):\n",
    "  true_class = nl_importance[i, 10]\n",
    "  estimated_class = c_nl_importance[nl_importance[i,0], nl_importance[i, 1], nl_importance[i, 2], nl_importance[i, 3], nl_importance[i,4]]\n",
    "  #print(\"true class is:\", true_class, \"estimated_class:\", estimated_class)\n",
    "  nl_importance_result.append(estimated_class)\n",
    "  if estimated_class == true_class:\n",
    "        nl_importance_correct += 1\n",
    "        \n",
    "accuracy = nl_importance_correct / len(nl_importance)\n",
    "print(\"\\nOverall Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b1323991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.8931506849315068\n"
     ]
    }
   ],
   "source": [
    "attributes = 10  \n",
    "classes = 10  \n",
    "values = 10  \n",
    "\n",
    "# Call the functions\n",
    "Q_al_importance = find_q(al_importance, attributes, classes, values)\n",
    "P_al_importance = find_p(al_importance, classes, values)\n",
    "c_al_importance = calculate_c(Q_al_importance, P_al_importance, values)\n",
    "al_importance_result = []\n",
    "al_importance_correct = 0\n",
    "for i in range(len(al_importance)):\n",
    "  true_class = al_importance[i, 10]\n",
    "  estimated_class = c_al_importance[al_importance[i,0], al_importance[i, 1], al_importance[i, 2], al_importance[i, 3], al_importance[i,4]]\n",
    "  #print(\"true class is:\", true_class, \"estimated_class:\", estimated_class)\n",
    "  al_importance_result.append(estimated_class)\n",
    "  if estimated_class == true_class:\n",
    "        al_importance_correct += 1\n",
    "\n",
    "accuracy = al_importance_correct / len(al_importance)\n",
    "print(\"\\nOverall Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b19b3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.8498583569405099\n"
     ]
    }
   ],
   "source": [
    "Q_nl_chi2 = find_q(nl_chi2, attributes, classes, values)\n",
    "P_nl_chi2 = find_p(nl_chi2, classes, values)\n",
    "c_nl_chi2 = calculate_c(Q_nl_chi2, P_nl_chi2, values)\n",
    "nl_chi2_result = []\n",
    "nl_chi2_correct = 0\n",
    "for i in range(len(nl_chi2)):\n",
    "  true_class = nl_chi2[i, 10]\n",
    "  estimated_class = c_nl_chi2[nl_chi2[i,0], nl_chi2[i, 1], nl_chi2[i, 2], nl_chi2[i, 3], nl_chi2[i,4]]\n",
    "  #print(\"true class is:\", true_class, \"estimated_class:\", estimated_class)\n",
    "  nl_chi2_result.append(estimated_class)\n",
    "  if estimated_class == true_class:\n",
    "        nl_chi2_correct += 1\n",
    "\n",
    "accuracy = nl_chi2_correct / len(nl_chi2)\n",
    "print(\"\\nOverall Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f195c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.8657534246575342\n"
     ]
    }
   ],
   "source": [
    "Q_al_chi2 = find_q(al_chi2, attributes, classes, values)\n",
    "P_al_chi2 = find_p(al_chi2, classes, values)\n",
    "c_al_chi2 = calculate_c(Q_al_chi2, P_al_chi2, values)\n",
    "al_chi2_result = []\n",
    "al_chi2_correct = 0\n",
    "for i in range(len(al_chi2)):\n",
    "  true_class = al_chi2[i, 10]\n",
    "  estimated_class = c_al_chi2[al_chi2[i,0], al_chi2[i, 1], al_chi2[i, 2], al_chi2[i, 3], al_chi2[i,4]]\n",
    "  #print(\"true class is:\", true_class, \"estimated_class:\", estimated_class)\n",
    "  al_chi2_result.append(estimated_class)\n",
    "  if estimated_class == true_class:\n",
    "        al_chi2_correct += 1\n",
    "\n",
    "accuracy = al_chi2_correct / len(al_chi2)\n",
    "print(\"\\nOverall Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ddc37ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep test data\n",
    "df_test = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "player_descriptors_test = df_test.iloc[:, :3]\n",
    "league = df_test['Lg']\n",
    "x_test = df_test.iloc[:, 3:-1]\n",
    "\n",
    "player_descriptors_nl = player_descriptors_test[league == 'NL'].reset_index(drop=True)\n",
    "player_descriptors_al = player_descriptors_test[league == 'AL'].reset_index(drop=True)\n",
    "\n",
    "# Add league temporarily for sorting\n",
    "x_test['Lg'] = league\n",
    "\n",
    "# Create separate datasets\n",
    "x_al_test = x_test[x_test['Lg'] == 'AL'].drop(columns=['Lg'])\n",
    "x_nl_test = x_test[x_test['Lg'] == 'NL'].drop(columns=['Lg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d6039ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Importance\n",
    "x_nl_importance_test = x_nl_test[selected_features_nl_importance]\n",
    "x_al_importance_test = x_al_test[selected_features_al_importance]\n",
    "\n",
    "# Chi-squared Features\n",
    "x_nl_chi2_test = x_nl_test[selected_features_nl_chi2]\n",
    "x_al_chi2_test = x_al_test[selected_features_al_chi2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2e02e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate nl based on importance\n",
    "nl_importance_test = bin_mlb_features(x_nl_importance_test)\n",
    "nl_importance_test = nl_importance_test.to_numpy()\n",
    "\n",
    "# generate AL based on importance\n",
    "al_importance_test = bin_mlb_features(x_al_importance_test)\n",
    "al_importance_test = al_importance_test.to_numpy()\n",
    "\n",
    "# generate NL based on chi squared importance\n",
    "nl_chi2_test = bin_mlb_features(x_nl_chi2_test)\n",
    "nl_chi2_test = nl_chi2_test.to_numpy()\n",
    "\n",
    "# generate AL based on chi squared importance\n",
    "al_chi2_test = bin_mlb_features(x_al_chi2_test)\n",
    "al_chi2_test = al_chi2_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bc517c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(test_data, attribute_indices, c_nl_importance):\n",
    "    predictions = []\n",
    "\n",
    "    for row in test_data:\n",
    "        attr_values = tuple(int(row[i]) for i in attribute_indices)\n",
    "        predicted_class = c_nl_importance[attr_values]\n",
    "        predictions.append(predicted_class)\n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "408405cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL forest importance predictions: [3. 4. 4.]\n",
      "Corresponding players:\n",
      "      Rk               Player    yr\n",
      "34  70.0          Kodai Senga  25.0\n",
      "2    9.0           Logan Webb  25.0\n",
      "41  85.0  Cristopher SÃ¡nchez*  25.0\n"
     ]
    }
   ],
   "source": [
    "attribute_indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "predictions = predict_test_data(nl_importance_test, attribute_indices, c_nl_importance)\n",
    "non_zero_indices = np.where(predictions != 0)[0]\n",
    "non_zero_predictions = predictions[non_zero_indices]\n",
    "sorted_non_zero_indices = non_zero_indices[np.argsort(non_zero_predictions)]\n",
    "lowest_three_indices = sorted_non_zero_indices[:3]\n",
    "lowest_players = player_descriptors_nl.iloc[lowest_three_indices]\n",
    "print(\"NL forest importance predictions:\", predictions[lowest_three_indices])\n",
    "print(\"Corresponding players:\")\n",
    "print(lowest_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fb4ad06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL forest importance predictions: [1. 1. 1.]\n",
      "Corresponding players:\n",
      "     Rk            Player    yr\n",
      "0   1.0        Max Fried*  25.0\n",
      "3   5.0  Garrett Crochet*  25.0\n",
      "6  10.0       Kris Bubic*  25.0\n"
     ]
    }
   ],
   "source": [
    "attribute_indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "predictions = predict_test_data(al_importance_test, attribute_indices, c_al_importance)\n",
    "non_zero_indices = np.where(predictions != 0)[0]\n",
    "non_zero_predictions = predictions[non_zero_indices]\n",
    "sorted_non_zero_indices = non_zero_indices[np.argsort(non_zero_predictions)]\n",
    "lowest_three_indices = sorted_non_zero_indices[:3]\n",
    "lowest_players = player_descriptors_al.iloc[lowest_three_indices]\n",
    "print(\"AL forest importance predictions:\", predictions[lowest_three_indices])\n",
    "print(\"Corresponding players:\")\n",
    "print(lowest_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cbf56981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL Chi2 predictions: [7. 7. 7.]\n",
      "Corresponding players:\n",
      "      Rk              Player    yr\n",
      "10  21.0       Hunter Greene  25.0\n",
      "12  23.0      Freddy Peralta  25.0\n",
      "14  27.0  Yoshinobu Yamamoto  25.0\n"
     ]
    }
   ],
   "source": [
    "attribute_indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "predictions = predict_test_data(nl_chi2_test, attribute_indices, c_nl_chi2)\n",
    "non_zero_indices = np.where(predictions != 0)[0]\n",
    "non_zero_predictions = predictions[non_zero_indices]\n",
    "sorted_non_zero_indices = non_zero_indices[np.argsort(non_zero_predictions)]\n",
    "lowest_three_indices = sorted_non_zero_indices[:3]\n",
    "lowest_players = player_descriptors_nl.iloc[lowest_three_indices]\n",
    "print(\"NL Chi2 predictions:\", predictions[lowest_three_indices])\n",
    "print(\"Corresponding players:\")\n",
    "print(lowest_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e7e0ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL Chi2 predictions: [2. 2. 2.]\n",
      "Corresponding players:\n",
      "    Rk            Player    yr\n",
      "1  3.0         Seth Lugo  25.0\n",
      "3  5.0  Garrett Crochet*  25.0\n",
      "4  6.0    Nathan Eovaldi  25.0\n"
     ]
    }
   ],
   "source": [
    "attribute_indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "predictions = predict_test_data(al_chi2_test, attribute_indices, c_al_chi2)\n",
    "non_zero_indices = np.where(predictions != 0)[0]\n",
    "non_zero_predictions = predictions[non_zero_indices]\n",
    "sorted_non_zero_indices = non_zero_indices[np.argsort(non_zero_predictions)]\n",
    "lowest_three_indices = sorted_non_zero_indices[:3]\n",
    "lowest_players = player_descriptors_al.iloc[lowest_three_indices]\n",
    "print(\"AL Chi2 predictions:\", predictions[lowest_three_indices])\n",
    "print(\"Corresponding players:\")\n",
    "print(lowest_players)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
